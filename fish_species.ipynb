{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d6f317b-3ab1-4892-9d6d-83eac11e30db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"Fish.csv\")\n",
    "\n",
    "# Encode the categorical variable\n",
    "le = LabelEncoder()\n",
    "df['Species'] = le.fit_transform(df['Species'])\n",
    "\n",
    "# Features and target variable\n",
    "X = df.drop(\"Species\", axis=1)\n",
    "y = df[\"Species\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "with open(\"model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "668e6444-5684-481f-98ad-8647f21ab8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Species  Weight  Length1  Length2  Length3   Height   Width\n",
      "0   Bream   242.0     23.2     25.4     30.0  11.5200  4.0200\n",
      "1   Bream   290.0     24.0     26.3     31.2  12.4800  4.3056\n",
      "2   Bream   340.0     23.9     26.5     31.1  12.3778  4.6961\n",
      "3   Bream   363.0     26.3     29.0     33.5  12.7300  4.4555\n",
      "4   Bream   430.0     26.5     29.0     34.0  12.4440  5.1340\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Fish.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "243f9a70-cfe6-45cf-8718-e3f931586229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species    0\n",
      "Weight     0\n",
      "Length1    0\n",
      "Length2    0\n",
      "Length3    0\n",
      "Height     0\n",
      "Width      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ef95435-609a-4716-8877-d2cd3666a24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159 entries, 0 to 158\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Species  159 non-null    int32  \n",
      " 1   Weight   159 non-null    float64\n",
      " 2   Length1  159 non-null    float64\n",
      " 3   Length2  159 non-null    float64\n",
      " 4   Length3  159 non-null    float64\n",
      " 5   Height   159 non-null    float64\n",
      " 6   Width    159 non-null    float64\n",
      "dtypes: float64(6), int32(1)\n",
      "memory usage: 8.2 KB\n",
      "None\n",
      "          Species       Weight     Length1     Length2     Length3  \\\n",
      "count  159.000000   159.000000  159.000000  159.000000  159.000000   \n",
      "mean     2.264151   398.326415   26.247170   28.415723   31.227044   \n",
      "std      1.704249   357.978317    9.996441   10.716328   11.610246   \n",
      "min      0.000000     0.000000    7.500000    8.400000    8.800000   \n",
      "25%      1.000000   120.000000   19.050000   21.000000   23.150000   \n",
      "50%      2.000000   273.000000   25.200000   27.300000   29.400000   \n",
      "75%      3.500000   650.000000   32.700000   35.500000   39.650000   \n",
      "max      6.000000  1650.000000   59.000000   63.400000   68.000000   \n",
      "\n",
      "           Height       Width  \n",
      "count  159.000000  159.000000  \n",
      "mean     8.970994    4.417486  \n",
      "std      4.286208    1.685804  \n",
      "min      1.728400    1.047600  \n",
      "25%      5.944800    3.385650  \n",
      "50%      7.786000    4.248500  \n",
      "75%     12.365900    5.584500  \n",
      "max     18.957000    8.142000  \n"
     ]
    }
   ],
   "source": [
    "# Check data types and summary\n",
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b76ba274-e2e4-46a4-8969-2680e9d1a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['Species'] = le.fit_transform(df['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fac7f017-761a-4d07-ad88-0f7a41748b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Species\", axis=1)\n",
    "y = df[\"Species\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7aa0b5f4-92e9-4d1b-a21f-af2981edab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "556b6466-09d8-4561-a9fe-df1e5d55f3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93         8\n",
      "           1       0.75      1.00      0.86         3\n",
      "           2       0.73      0.92      0.81        12\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       0.50      0.20      0.29         5\n",
      "           5       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.81        32\n",
      "   macro avg       0.83      0.83      0.82        32\n",
      "weighted avg       0.80      0.81      0.79        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94         8\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       1.00      1.00      1.00        12\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       0.71      1.00      0.83         5\n",
      "           5       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.91        32\n",
      "   macro avg       0.77      0.83      0.80        32\n",
      "weighted avg       0.83      0.91      0.87        32\n",
      "\n",
      "0.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nisha\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\nisha\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nisha\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nisha\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "ranfor = RandomForestClassifier()\n",
    "ranfor.fit(X_train, y_train)\n",
    "y_pred = ranfor.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "logreg = LogisticRegression(random_state=16)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "if (rf_accuracy > lr_accuracy):\n",
    "    model = rf_accuracy\n",
    "else:\n",
    "    model = lr_accuracy\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18cffdbc-7919-41a2-9677-57429f5dda3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c9c71b-ea0e-4499-b253-8a8b0b63b1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
